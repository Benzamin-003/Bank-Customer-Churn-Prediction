{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "826365c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "03a0cbe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>country</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>products_number</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15634602</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15647311</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15619304</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15701354</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15737888</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>15606229</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>15569892</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>15584532</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>15682355</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>15628319</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      customer_id  credit_score  country  gender  age  tenure    balance  \\\n",
       "0        15634602           619   France  Female   42       2       0.00   \n",
       "1        15647311           608    Spain  Female   41       1   83807.86   \n",
       "2        15619304           502   France  Female   42       8  159660.80   \n",
       "3        15701354           699   France  Female   39       1       0.00   \n",
       "4        15737888           850    Spain  Female   43       2  125510.82   \n",
       "...           ...           ...      ...     ...  ...     ...        ...   \n",
       "9995     15606229           771   France    Male   39       5       0.00   \n",
       "9996     15569892           516   France    Male   35      10   57369.61   \n",
       "9997     15584532           709   France  Female   36       7       0.00   \n",
       "9998     15682355           772  Germany    Male   42       3   75075.31   \n",
       "9999     15628319           792   France  Female   28       4  130142.79   \n",
       "\n",
       "      products_number  credit_card  active_member  estimated_salary  churn  \n",
       "0                   1            1              1         101348.88      1  \n",
       "1                   1            0              1         112542.58      0  \n",
       "2                   3            1              0         113931.57      1  \n",
       "3                   2            0              0          93826.63      0  \n",
       "4                   1            1              1          79084.10      0  \n",
       "...               ...          ...            ...               ...    ...  \n",
       "9995                2            1              0          96270.64      0  \n",
       "9996                1            1              1         101699.77      0  \n",
       "9997                1            0              1          42085.58      1  \n",
       "9998                2            1              0          92888.52      1  \n",
       "9999                1            1              0          38190.78      0  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Bank Customer Churn Prediction.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f468bc00",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "104a10b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_score</th>\n",
       "      <th>country</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>products_number</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      credit_score  country  gender  age  tenure    balance  products_number  \\\n",
       "0              619   France  Female   42       2       0.00                1   \n",
       "1              608    Spain  Female   41       1   83807.86                1   \n",
       "2              502   France  Female   42       8  159660.80                3   \n",
       "3              699   France  Female   39       1       0.00                2   \n",
       "4              850    Spain  Female   43       2  125510.82                1   \n",
       "...            ...      ...     ...  ...     ...        ...              ...   \n",
       "9995           771   France    Male   39       5       0.00                2   \n",
       "9996           516   France    Male   35      10   57369.61                1   \n",
       "9997           709   France  Female   36       7       0.00                1   \n",
       "9998           772  Germany    Male   42       3   75075.31                2   \n",
       "9999           792   France  Female   28       4  130142.79                1   \n",
       "\n",
       "      credit_card  active_member  estimated_salary  churn  \n",
       "0               1              1         101348.88      1  \n",
       "1               0              1         112542.58      0  \n",
       "2               1              0         113931.57      1  \n",
       "3               0              0          93826.63      0  \n",
       "4               1              1          79084.10      0  \n",
       "...           ...            ...               ...    ...  \n",
       "9995            1              0          96270.64      0  \n",
       "9996            1              1         101699.77      0  \n",
       "9997            0              1          42085.58      1  \n",
       "9998            1              0          92888.52      1  \n",
       "9999            1              0          38190.78      0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns='customer_id')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e4f93a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "France     5014\n",
       "Germany    2509\n",
       "Spain      2477\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3b7b077e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_score</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>products_number</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>churn</th>\n",
       "      <th>country_France</th>\n",
       "      <th>country_Germany</th>\n",
       "      <th>country_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      credit_score  gender  age  tenure    balance  products_number  \\\n",
       "0              619  Female   42       2       0.00                1   \n",
       "1              608  Female   41       1   83807.86                1   \n",
       "2              502  Female   42       8  159660.80                3   \n",
       "3              699  Female   39       1       0.00                2   \n",
       "4              850  Female   43       2  125510.82                1   \n",
       "...            ...     ...  ...     ...        ...              ...   \n",
       "9995           771    Male   39       5       0.00                2   \n",
       "9996           516    Male   35      10   57369.61                1   \n",
       "9997           709  Female   36       7       0.00                1   \n",
       "9998           772    Male   42       3   75075.31                2   \n",
       "9999           792  Female   28       4  130142.79                1   \n",
       "\n",
       "      credit_card  active_member  estimated_salary  churn  country_France  \\\n",
       "0               1              1         101348.88      1               1   \n",
       "1               0              1         112542.58      0               0   \n",
       "2               1              0         113931.57      1               1   \n",
       "3               0              0          93826.63      0               1   \n",
       "4               1              1          79084.10      0               0   \n",
       "...           ...            ...               ...    ...             ...   \n",
       "9995            1              0          96270.64      0               1   \n",
       "9996            1              1         101699.77      0               1   \n",
       "9997            0              1          42085.58      1               1   \n",
       "9998            1              0          92888.52      1               0   \n",
       "9999            1              0          38190.78      0               1   \n",
       "\n",
       "      country_Germany  country_Spain  \n",
       "0                   0              0  \n",
       "1                   0              1  \n",
       "2                   0              0  \n",
       "3                   0              0  \n",
       "4                   0              1  \n",
       "...               ...            ...  \n",
       "9995                0              0  \n",
       "9996                0              0  \n",
       "9997                0              0  \n",
       "9998                1              0  \n",
       "9999                0              0  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df, columns=['country'], dtype='int')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3fe248d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_8360\\1306303817.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['gender'] = df['gender'].replace(size_mapping)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_score</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>products_number</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>churn</th>\n",
       "      <th>country_France</th>\n",
       "      <th>country_Germany</th>\n",
       "      <th>country_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      credit_score  gender  age  tenure    balance  products_number  \\\n",
       "0              619       1   42       2       0.00                1   \n",
       "1              608       1   41       1   83807.86                1   \n",
       "2              502       1   42       8  159660.80                3   \n",
       "3              699       1   39       1       0.00                2   \n",
       "4              850       1   43       2  125510.82                1   \n",
       "...            ...     ...  ...     ...        ...              ...   \n",
       "9995           771       0   39       5       0.00                2   \n",
       "9996           516       0   35      10   57369.61                1   \n",
       "9997           709       1   36       7       0.00                1   \n",
       "9998           772       0   42       3   75075.31                2   \n",
       "9999           792       1   28       4  130142.79                1   \n",
       "\n",
       "      credit_card  active_member  estimated_salary  churn  country_France  \\\n",
       "0               1              1         101348.88      1               1   \n",
       "1               0              1         112542.58      0               0   \n",
       "2               1              0         113931.57      1               1   \n",
       "3               0              0          93826.63      0               1   \n",
       "4               1              1          79084.10      0               0   \n",
       "...           ...            ...               ...    ...             ...   \n",
       "9995            1              0          96270.64      0               1   \n",
       "9996            1              1         101699.77      0               1   \n",
       "9997            0              1          42085.58      1               1   \n",
       "9998            1              0          92888.52      1               0   \n",
       "9999            1              0          38190.78      0               1   \n",
       "\n",
       "      country_Germany  country_Spain  \n",
       "0                   0              0  \n",
       "1                   0              1  \n",
       "2                   0              0  \n",
       "3                   0              0  \n",
       "4                   0              1  \n",
       "...               ...            ...  \n",
       "9995                0              0  \n",
       "9996                0              0  \n",
       "9997                0              0  \n",
       "9998                1              0  \n",
       "9999                0              0  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_mapping = {'Male':0, 'Female':1, }\n",
    "df['gender'] = df['gender'].replace(size_mapping)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a9968b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "9995    0\n",
       "9996    0\n",
       "9997    1\n",
       "9998    1\n",
       "9999    0\n",
       "Name: churn, Length: 10000, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['churn']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "708df12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['credit_score', 'gender', 'age', 'tenure', 'balance', 'products_number',\n",
       "       'credit_card', 'active_member', 'estimated_salary', 'country_France',\n",
       "       'country_Germany', 'country_Spain'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.drop(['churn'], axis=1)\n",
    "x.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2038c7f1",
   "metadata": {},
   "source": [
    "# Without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8ce7572b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 12), (3000, 12), (7000,), (3000,))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1c74492b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      credit_score  gender  age  tenure    balance  products_number  \\\n",
      "0              619       1   42       2       0.00                1   \n",
      "1              608       1   41       1   83807.86                1   \n",
      "2              502       1   42       8  159660.80                3   \n",
      "3              699       1   39       1       0.00                2   \n",
      "4              850       1   43       2  125510.82                1   \n",
      "...            ...     ...  ...     ...        ...              ...   \n",
      "9995           771       0   39       5       0.00                2   \n",
      "9996           516       0   35      10   57369.61                1   \n",
      "9997           709       1   36       7       0.00                1   \n",
      "9998           772       0   42       3   75075.31                2   \n",
      "9999           792       1   28       4  130142.79                1   \n",
      "\n",
      "      credit_card  active_member  estimated_salary  churn  country_France  \\\n",
      "0               1              1         101348.88      1               1   \n",
      "1               0              1         112542.58      0               0   \n",
      "2               1              0         113931.57      1               1   \n",
      "3               0              0          93826.63      0               1   \n",
      "4               1              1          79084.10      0               0   \n",
      "...           ...            ...               ...    ...             ...   \n",
      "9995            1              0          96270.64      0               1   \n",
      "9996            1              1         101699.77      0               1   \n",
      "9997            0              1          42085.58      1               1   \n",
      "9998            1              0          92888.52      1               0   \n",
      "9999            1              0          38190.78      0               1   \n",
      "\n",
      "      country_Germany  country_Spain  \n",
      "0                   0              0  \n",
      "1                   0              1  \n",
      "2                   0              0  \n",
      "3                   0              0  \n",
      "4                   0              1  \n",
      "...               ...            ...  \n",
      "9995                0              0  \n",
      "9996                0              0  \n",
      "9997                0              0  \n",
      "9998                1              0  \n",
      "9999                0              0  \n",
      "\n",
      "[10000 rows x 13 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-0.34459497,  1.09823226, -0.65674999, ..., -1.00171576,\n",
       "         -0.57559072,  1.73073215],\n",
       "        [-0.09518109,  1.09823226, -0.46637979, ..., -1.00171576,\n",
       "          1.73734559, -0.57779016],\n",
       "        [-0.94734518, -0.91055421, -0.56156489, ...,  0.99828718,\n",
       "         -0.57559072, -0.57779016],\n",
       "        ...,\n",
       "        [ 0.86090545,  1.09823226, -0.08563939, ...,  0.99828718,\n",
       "         -0.57559072, -0.57779016],\n",
       "        [ 0.15423279, -0.91055421,  0.39028611, ...,  0.99828718,\n",
       "         -0.57559072, -0.57779016],\n",
       "        [ 0.46600014, -0.91055421,  1.1517669 , ..., -1.00171576,\n",
       "          1.73734559, -0.57779016]]),\n",
       " array([[-0.5836166 , -0.91055421, -0.65674999, ..., -1.00171576,\n",
       "          1.73734559, -0.57779016],\n",
       "        [-0.30302599, -0.91055421,  0.39028611, ...,  0.99828718,\n",
       "         -0.57559072, -0.57779016],\n",
       "        [-0.53165538,  1.09823226,  0.48547121, ..., -1.00171576,\n",
       "         -0.57559072,  1.73073215],\n",
       "        ...,\n",
       "        [-0.44851742, -0.91055421, -0.65674999, ...,  0.99828718,\n",
       "         -0.57559072, -0.57779016],\n",
       "        [-0.74989252, -0.91055421, -0.75193509, ...,  0.99828718,\n",
       "         -0.57559072, -0.57779016],\n",
       "        [-1.23832804,  1.09823226, -1.60860099, ..., -1.00171576,\n",
       "          1.73734559, -0.57779016]]))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(df)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(x_train)\n",
    "X_test_scaled = scaler.transform(x_test)\n",
    "X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c40799a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9069    1\n",
       "2603    0\n",
       "7738    0\n",
       "1579    0\n",
       "5058    0\n",
       "       ..\n",
       "5734    0\n",
       "5191    0\n",
       "5390    1\n",
       "860     1\n",
       "7270    0\n",
       "Name: churn, Length: 7000, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "240222ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "08117b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8113333333333334\n",
      "Precision: 0.5420560747663551\n",
      "Recall: 0.19863013698630136\n",
      "F1 Score: 0.2907268170426065\n",
      "confusion_matrix\n",
      " [[2318   98]\n",
      " [ 468  116]]\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"confusion_matrix\\n\",conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "63b1496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC(kernel='poly',probability=True,random_state=42)\n",
    "svc_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_svc_pred = svc_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "59c1bb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8616666666666667\n",
      "Precision: 0.83399209486166\n",
      "Recall: 0.3613013698630137\n",
      "F1 Score: 0.5041816009557945\n",
      "confusion_matrix\n",
      " [[2374   42]\n",
      " [ 373  211]]\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_svc_pred)\n",
    "precision = precision_score(y_test, y_svc_pred)\n",
    "recall = recall_score(y_test, y_svc_pred)\n",
    "f1 = f1_score(y_test, y_svc_pred)\n",
    "conf_svc_matrix = confusion_matrix(y_test, y_svc_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"confusion_matrix\\n\",conf_svc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0d651e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a50fd062",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "41c57827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82285714 0.81714286 0.80571429 0.79571429 0.81142857 0.82\n",
      " 0.79142857 0.80571429 0.82142857 0.80285714]\n"
     ]
    }
   ],
   "source": [
    "cross_val_acc = cross_val_score(model, X_train_scaled, y_train, cv=kf)\n",
    "\n",
    "print(cross_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "636861de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82285714 0.81714286 0.80571429 0.79571429 0.81142857 0.82\n",
      " 0.79142857 0.80571429 0.82142857 0.80285714]\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "cross_val_acc = cross_val_score(model, X_train_scaled, y_train, cv=kf)\n",
    "\n",
    "print(cross_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "37c566d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.344595</td>\n",
       "      <td>1.098232</td>\n",
       "      <td>-0.656750</td>\n",
       "      <td>-0.342170</td>\n",
       "      <td>1.583725</td>\n",
       "      <td>0.819663</td>\n",
       "      <td>0.645981</td>\n",
       "      <td>0.970714</td>\n",
       "      <td>1.248214</td>\n",
       "      <td>-1.001716</td>\n",
       "      <td>-0.575591</td>\n",
       "      <td>1.730732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.095181</td>\n",
       "      <td>1.098232</td>\n",
       "      <td>-0.466380</td>\n",
       "      <td>0.698162</td>\n",
       "      <td>1.344106</td>\n",
       "      <td>-0.903352</td>\n",
       "      <td>-1.548034</td>\n",
       "      <td>0.970714</td>\n",
       "      <td>1.521225</td>\n",
       "      <td>-1.001716</td>\n",
       "      <td>1.737346</td>\n",
       "      <td>-0.577790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.947345</td>\n",
       "      <td>-0.910554</td>\n",
       "      <td>-0.561565</td>\n",
       "      <td>0.351385</td>\n",
       "      <td>-1.222055</td>\n",
       "      <td>0.819663</td>\n",
       "      <td>-1.548034</td>\n",
       "      <td>-1.030169</td>\n",
       "      <td>1.263615</td>\n",
       "      <td>0.998287</td>\n",
       "      <td>-0.575591</td>\n",
       "      <td>-0.577790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.354987</td>\n",
       "      <td>-0.910554</td>\n",
       "      <td>0.199916</td>\n",
       "      <td>1.044940</td>\n",
       "      <td>-0.618965</td>\n",
       "      <td>-0.903352</td>\n",
       "      <td>0.645981</td>\n",
       "      <td>0.970714</td>\n",
       "      <td>1.646839</td>\n",
       "      <td>-1.001716</td>\n",
       "      <td>1.737346</td>\n",
       "      <td>-0.577790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.642668</td>\n",
       "      <td>-0.910554</td>\n",
       "      <td>-0.180824</td>\n",
       "      <td>1.391718</td>\n",
       "      <td>1.152808</td>\n",
       "      <td>0.819663</td>\n",
       "      <td>-1.548034</td>\n",
       "      <td>0.970714</td>\n",
       "      <td>0.875112</td>\n",
       "      <td>0.998287</td>\n",
       "      <td>-0.575591</td>\n",
       "      <td>-0.577790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>1.203850</td>\n",
       "      <td>-0.910554</td>\n",
       "      <td>1.437322</td>\n",
       "      <td>1.044940</td>\n",
       "      <td>-0.106936</td>\n",
       "      <td>-0.903352</td>\n",
       "      <td>0.645981</td>\n",
       "      <td>0.970714</td>\n",
       "      <td>-0.545387</td>\n",
       "      <td>0.998287</td>\n",
       "      <td>-0.575591</td>\n",
       "      <td>-0.577790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>0.310116</td>\n",
       "      <td>1.098232</td>\n",
       "      <td>1.818063</td>\n",
       "      <td>-1.382503</td>\n",
       "      <td>-1.222055</td>\n",
       "      <td>-0.903352</td>\n",
       "      <td>0.645981</td>\n",
       "      <td>0.970714</td>\n",
       "      <td>-1.736501</td>\n",
       "      <td>0.998287</td>\n",
       "      <td>-0.575591</td>\n",
       "      <td>-0.577790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>0.860905</td>\n",
       "      <td>1.098232</td>\n",
       "      <td>-0.085639</td>\n",
       "      <td>-1.382503</td>\n",
       "      <td>-1.222055</td>\n",
       "      <td>2.542677</td>\n",
       "      <td>-1.548034</td>\n",
       "      <td>-1.030169</td>\n",
       "      <td>-0.149259</td>\n",
       "      <td>0.998287</td>\n",
       "      <td>-0.575591</td>\n",
       "      <td>-0.577790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>0.154233</td>\n",
       "      <td>-0.910554</td>\n",
       "      <td>0.390286</td>\n",
       "      <td>1.044940</td>\n",
       "      <td>1.820806</td>\n",
       "      <td>-0.903352</td>\n",
       "      <td>0.645981</td>\n",
       "      <td>-1.030169</td>\n",
       "      <td>-0.057544</td>\n",
       "      <td>0.998287</td>\n",
       "      <td>-0.575591</td>\n",
       "      <td>-0.577790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>0.466000</td>\n",
       "      <td>-0.910554</td>\n",
       "      <td>1.151767</td>\n",
       "      <td>-1.382503</td>\n",
       "      <td>1.143904</td>\n",
       "      <td>-0.903352</td>\n",
       "      <td>0.645981</td>\n",
       "      <td>0.970714</td>\n",
       "      <td>-0.819426</td>\n",
       "      <td>-1.001716</td>\n",
       "      <td>1.737346</td>\n",
       "      <td>-0.577790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0    -0.344595  1.098232 -0.656750 -0.342170  1.583725  0.819663  0.645981   \n",
       "1    -0.095181  1.098232 -0.466380  0.698162  1.344106 -0.903352 -1.548034   \n",
       "2    -0.947345 -0.910554 -0.561565  0.351385 -1.222055  0.819663 -1.548034   \n",
       "3    -0.354987 -0.910554  0.199916  1.044940 -0.618965 -0.903352  0.645981   \n",
       "4     0.642668 -0.910554 -0.180824  1.391718  1.152808  0.819663 -1.548034   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6995  1.203850 -0.910554  1.437322  1.044940 -0.106936 -0.903352  0.645981   \n",
       "6996  0.310116  1.098232  1.818063 -1.382503 -1.222055 -0.903352  0.645981   \n",
       "6997  0.860905  1.098232 -0.085639 -1.382503 -1.222055  2.542677 -1.548034   \n",
       "6998  0.154233 -0.910554  0.390286  1.044940  1.820806 -0.903352  0.645981   \n",
       "6999  0.466000 -0.910554  1.151767 -1.382503  1.143904 -0.903352  0.645981   \n",
       "\n",
       "            7         8         9         10        11  \n",
       "0     0.970714  1.248214 -1.001716 -0.575591  1.730732  \n",
       "1     0.970714  1.521225 -1.001716  1.737346 -0.577790  \n",
       "2    -1.030169  1.263615  0.998287 -0.575591 -0.577790  \n",
       "3     0.970714  1.646839 -1.001716  1.737346 -0.577790  \n",
       "4     0.970714  0.875112  0.998287 -0.575591 -0.577790  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "6995  0.970714 -0.545387  0.998287 -0.575591 -0.577790  \n",
       "6996  0.970714 -1.736501  0.998287 -0.575591 -0.577790  \n",
       "6997 -1.030169 -0.149259  0.998287 -0.575591 -0.577790  \n",
       "6998 -1.030169 -0.057544  0.998287 -0.575591 -0.577790  \n",
       "6999  0.970714 -0.819426 -1.001716  1.737346 -0.577790  \n",
       "\n",
       "[7000 rows x 12 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled = pd.DataFrame(X_train_scaled)\n",
    "x_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1f54465c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9069</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2603</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7738</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5058</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      churn\n",
       "9069      1\n",
       "2603      0\n",
       "7738      0\n",
       "1579      0\n",
       "5058      0\n",
       "...     ...\n",
       "5734      0\n",
       "5191      0\n",
       "5390      1\n",
       "860       1\n",
       "7270      0\n",
       "\n",
       "[7000 rows x 1 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.DataFrame(y_train)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "39132e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Fold 1 - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.89       554\n",
      "           1       0.65      0.24      0.35       146\n",
      "\n",
      "    accuracy                           0.81       700\n",
      "   macro avg       0.74      0.60      0.62       700\n",
      "weighted avg       0.79      0.81      0.78       700\n",
      "\n",
      "------------------------------------------------\n",
      "📂 Fold 2 - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88       554\n",
      "           1       0.53      0.17      0.26       146\n",
      "\n",
      "    accuracy                           0.80       700\n",
      "   macro avg       0.67      0.57      0.57       700\n",
      "weighted avg       0.76      0.80      0.75       700\n",
      "\n",
      "------------------------------------------------\n",
      "📂 Fold 3 - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.89       554\n",
      "           1       0.59      0.21      0.30       146\n",
      "\n",
      "    accuracy                           0.80       700\n",
      "   macro avg       0.70      0.58      0.60       700\n",
      "weighted avg       0.77      0.80      0.76       700\n",
      "\n",
      "------------------------------------------------\n",
      "📂 Fold 4 - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89       555\n",
      "           1       0.61      0.21      0.31       145\n",
      "\n",
      "    accuracy                           0.81       700\n",
      "   macro avg       0.72      0.59      0.60       700\n",
      "weighted avg       0.78      0.81      0.77       700\n",
      "\n",
      "------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Fold 5 - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89       555\n",
      "           1       0.63      0.23      0.34       145\n",
      "\n",
      "    accuracy                           0.81       700\n",
      "   macro avg       0.73      0.60      0.62       700\n",
      "weighted avg       0.79      0.81      0.78       700\n",
      "\n",
      "------------------------------------------------\n",
      "📂 Fold 6 - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.88       555\n",
      "           1       0.56      0.20      0.29       145\n",
      "\n",
      "    accuracy                           0.80       700\n",
      "   macro avg       0.69      0.58      0.59       700\n",
      "weighted avg       0.77      0.80      0.76       700\n",
      "\n",
      "------------------------------------------------\n",
      "📂 Fold 7 - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.89       555\n",
      "           1       0.57      0.22      0.32       145\n",
      "\n",
      "    accuracy                           0.80       700\n",
      "   macro avg       0.70      0.59      0.60       700\n",
      "weighted avg       0.77      0.80      0.77       700\n",
      "\n",
      "------------------------------------------------\n",
      "📂 Fold 8 - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90       555\n",
      "           1       0.74      0.29      0.42       145\n",
      "\n",
      "    accuracy                           0.83       700\n",
      "   macro avg       0.79      0.63      0.66       700\n",
      "weighted avg       0.82      0.83      0.80       700\n",
      "\n",
      "------------------------------------------------\n",
      "📂 Fold 9 - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.88       555\n",
      "           1       0.55      0.19      0.28       145\n",
      "\n",
      "    accuracy                           0.80       700\n",
      "   macro avg       0.68      0.57      0.58       700\n",
      "weighted avg       0.76      0.80      0.76       700\n",
      "\n",
      "------------------------------------------------\n",
      "📂 Fold 10 - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89       555\n",
      "           1       0.64      0.27      0.38       145\n",
      "\n",
      "    accuracy                           0.82       700\n",
      "   macro avg       0.74      0.61      0.64       700\n",
      "weighted avg       0.79      0.82      0.79       700\n",
      "\n",
      "------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "fold = 1\n",
    "for train_idx, test_idx in skf.split(x_train_scaled, y_train):\n",
    "    X_train, X_test = x_train_scaled.iloc[train_idx], x_train_scaled.iloc[test_idx]\n",
    "    y_trained, y_test = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "    \n",
    "    model.fit(X_train, y_trained)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(f\"📂 Fold {fold} - Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"------------------------------------------------\")\n",
    "    fold +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a4fa18",
   "metadata": {},
   "source": [
    "# With SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6a528a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "churn\n",
      "1    5972\n",
      "0    5972\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "churn\n",
       "0    5972\n",
       "1    1528\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN, SMOTEN\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42, stratify=y)\n",
    "\n",
    "sm = SMOTEN( k_neighbors=20, random_state=42)\n",
    "x_sampled, y_sampled = sm.fit_resample(x_train, y_train)\n",
    "print(y_sampled.value_counts())\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "684a7df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.99779864,  0.97127638,  1.28563063, ...,  1.05456777,\n",
       "         -0.66128999, -0.52723798],\n",
       "        [-1.01615685, -1.02957307, -0.27034094, ...,  1.05456777,\n",
       "         -0.66128999, -0.52723798],\n",
       "        [-0.51498821,  0.97127638,  1.38936207, ..., -0.9482558 ,\n",
       "          1.51219588, -0.52723798],\n",
       "        ...,\n",
       "        [-1.31314568,  0.97127638,  0.87070488, ..., -0.9482558 ,\n",
       "          1.51219588, -0.52723798],\n",
       "        [-1.03471866,  0.97127638,  0.76697344, ..., -0.9482558 ,\n",
       "          1.51219588, -0.52723798],\n",
       "        [-1.37811199, -1.02957307,  0.04085337, ..., -0.9482558 ,\n",
       "          1.51219588, -0.52723798]]),\n",
       " array([[ 0.06970855,  0.97127638, -0.68526669, ..., -0.9482558 ,\n",
       "         -0.66128999,  1.89667673],\n",
       "        [ 1.20197846, -1.02957307, -1.10019244, ..., -0.9482558 ,\n",
       "         -0.66128999,  1.89667673],\n",
       "        [ 0.31101197,  0.97127638, -0.58153525, ..., -0.9482558 ,\n",
       "          1.51219588, -0.52723798],\n",
       "        ...,\n",
       "        [-0.66348262,  0.97127638,  1.07816775, ...,  1.05456777,\n",
       "         -0.66128999, -0.52723798],\n",
       "        [ 0.13467485,  0.97127638,  1.4930935 , ...,  1.05456777,\n",
       "         -0.66128999, -0.52723798],\n",
       "        [ 0.6636862 , -1.02957307, -0.47780382, ..., -0.9482558 ,\n",
       "          1.51219588, -0.52723798]]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_sampled)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "x_train_scaled, x_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a72a7e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores for each fold: [0.82796149 0.83298451 0.82628715 0.80410213 0.82160804]\n",
      "Mean Accuracy: 0.8226\n",
      "Standard Deviation: 0.0099\n",
      "\n",
      "Fold 1 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81      1206\n",
      "           1       0.79      0.83      0.81      1183\n",
      "\n",
      "    accuracy                           0.81      2389\n",
      "   macro avg       0.81      0.81      0.81      2389\n",
      "weighted avg       0.81      0.81      0.81      2389\n",
      "\n",
      "\n",
      "Fold 2 Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80      1194\n",
      "           1       0.80      0.81      0.81      1195\n",
      "\n",
      "    accuracy                           0.80      2389\n",
      "   macro avg       0.80      0.80      0.80      2389\n",
      "weighted avg       0.80      0.80      0.80      2389\n",
      "\n",
      "\n",
      "Fold 3 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.81      1230\n",
      "           1       0.79      0.84      0.82      1159\n",
      "\n",
      "    accuracy                           0.81      2389\n",
      "   macro avg       0.82      0.82      0.81      2389\n",
      "weighted avg       0.82      0.81      0.81      2389\n",
      "\n",
      "\n",
      "Fold 4 Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78      1153\n",
      "           1       0.79      0.81      0.80      1236\n",
      "\n",
      "    accuracy                           0.79      2389\n",
      "   macro avg       0.79      0.79      0.79      2389\n",
      "weighted avg       0.79      0.79      0.79      2389\n",
      "\n",
      "\n",
      "Fold 5 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.77      0.79      1189\n",
      "           1       0.78      0.84      0.81      1199\n",
      "\n",
      "    accuracy                           0.80      2388\n",
      "   macro avg       0.80      0.80      0.80      2388\n",
      "weighted avg       0.80      0.80      0.80      2388\n",
      "\n",
      "Test Accuracy: 0.6748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.70      0.77      1991\n",
      "           1       0.33      0.59      0.42       509\n",
      "\n",
      "    accuracy                           0.67      2500\n",
      "   macro avg       0.60      0.64      0.60      2500\n",
      "weighted avg       0.76      0.67      0.70      2500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score,cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scores = cross_val_score(logistic_model, x_train_scaled, y_sampled, cv=kf, scoring='accuracy')\n",
    "\n",
    "print(f\"Accuracy scores for each fold: {scores}\")\n",
    "print(f\"Mean Accuracy: {np.mean(scores):.4f}\")\n",
    "print(f\"Standard Deviation: {np.std(scores):.4f}\")\n",
    "\n",
    "\n",
    "x_sampled = pd.DataFrame(x_sampled)\n",
    "y_train = pd.Series(y_train)\n",
    "fold = 1\n",
    "for train_idx, val_idx in kf.split(x_sampled, y_sampled):\n",
    "    logistic_model.fit(x_sampled.iloc[train_idx], y_sampled.iloc[train_idx])\n",
    "    y_val_pred = logistic_model.predict(x_sampled.iloc[val_idx])\n",
    "    print(f\"\\nFold {fold} Classification Report:\")\n",
    "    print(classification_report(y_sampled.iloc[val_idx], y_val_pred))\n",
    "    fold += 1\n",
    "\n",
    "logistic_model.fit(x_sampled, y_sampled)\n",
    "y_pred = logistic_model.predict(x_test_scaled)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "128a28b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.70      0.77      1991\n",
      "           1       0.33      0.59      0.42       509\n",
      "\n",
      "    accuracy                           0.67      2500\n",
      "   macro avg       0.60      0.64      0.60      2500\n",
      "weighted avg       0.76      0.67      0.70      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "67a042a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores for each fold: [0.87316869 0.87902888 0.88195898 0.85893679 0.87102178]\n",
      "Mean Accuracy: 0.8728\n",
      "Standard Deviation: 0.0080\n",
      "\n",
      "Fold 1 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88      1206\n",
      "           1       0.90      0.84      0.87      1183\n",
      "\n",
      "    accuracy                           0.87      2389\n",
      "   macro avg       0.87      0.87      0.87      2389\n",
      "weighted avg       0.87      0.87      0.87      2389\n",
      "\n",
      "\n",
      "Fold 2 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88      1194\n",
      "           1       0.90      0.85      0.88      1195\n",
      "\n",
      "    accuracy                           0.88      2389\n",
      "   macro avg       0.88      0.88      0.88      2389\n",
      "weighted avg       0.88      0.88      0.88      2389\n",
      "\n",
      "\n",
      "Fold 3 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89      1230\n",
      "           1       0.89      0.87      0.88      1159\n",
      "\n",
      "    accuracy                           0.88      2389\n",
      "   macro avg       0.88      0.88      0.88      2389\n",
      "weighted avg       0.88      0.88      0.88      2389\n",
      "\n",
      "\n",
      "Fold 4 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86      1153\n",
      "           1       0.89      0.83      0.86      1236\n",
      "\n",
      "    accuracy                           0.86      2389\n",
      "   macro avg       0.86      0.86      0.86      2389\n",
      "weighted avg       0.86      0.86      0.86      2389\n",
      "\n",
      "\n",
      "Fold 5 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87      1189\n",
      "           1       0.89      0.85      0.87      1199\n",
      "\n",
      "    accuracy                           0.87      2388\n",
      "   macro avg       0.87      0.87      0.87      2388\n",
      "weighted avg       0.87      0.87      0.87      2388\n",
      "\n",
      "Test Accuracy: 0.8044\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88      1991\n",
      "           1       0.52      0.45      0.48       509\n",
      "\n",
      "    accuracy                           0.80      2500\n",
      "   macro avg       0.69      0.67      0.68      2500\n",
      "weighted avg       0.79      0.80      0.80      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(knn_model, x_train_scaled, y_sampled, cv=kf, scoring='accuracy')\n",
    "\n",
    "print(f\"Accuracy scores for each fold: {scores}\")\n",
    "print(f\"Mean Accuracy: {np.mean(scores):.4f}\")\n",
    "print(f\"Standard Deviation: {np.std(scores):.4f}\")\n",
    "\n",
    "\n",
    "x_train_scaled = pd.DataFrame(x_train_scaled)\n",
    "y_train = pd.Series(y_train)\n",
    "fold = 1\n",
    "for train_idx, val_idx in kf.split(x_train_scaled, y_sampled):\n",
    "    knn_model.fit(x_train_scaled.iloc[train_idx], y_sampled.iloc[train_idx])\n",
    "    y_val_pred = knn_model.predict(x_train_scaled.iloc[val_idx])\n",
    "    print(f\"\\nFold {fold} Classification Report:\")\n",
    "    print(classification_report(y_sampled.iloc[val_idx], y_val_pred))\n",
    "    fold += 1\n",
    "\n",
    "knn_model.fit(x_train_scaled, y_sampled)\n",
    "y_pred = knn_model.predict(x_test_scaled)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f98f1194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores for each fold: [0.89995814 0.89870239 0.89786522 0.8756802  0.89237856]\n",
      "Mean Accuracy: 0.8929\n",
      "Standard Deviation: 0.0090\n",
      "Test Accuracy: 0.8444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91      1991\n",
      "           1       0.66      0.48      0.56       509\n",
      "\n",
      "    accuracy                           0.84      2500\n",
      "   macro avg       0.77      0.71      0.73      2500\n",
      "weighted avg       0.83      0.84      0.83      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC(kernel='rbf', random_state=42)\n",
    "skf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(svc_model, x_train_scaled, y_sampled, cv=kf, scoring='accuracy')\n",
    "\n",
    "print(f\"Accuracy scores for each fold: {scores}\")\n",
    "print(f\"Mean Accuracy: {np.mean(scores):.4f}\")\n",
    "print(f\"Standard Deviation: {np.std(scores):.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "svc_model.fit(x_train_scaled, y_sampled)\n",
    "y_pred = svc_model.predict(x_test_scaled)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8de9d700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91      1991\n",
      "           1       0.66      0.48      0.56       509\n",
      "\n",
      "    accuracy                           0.84      2500\n",
      "   macro avg       0.77      0.71      0.73      2500\n",
      "weighted avg       0.83      0.84      0.83      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
